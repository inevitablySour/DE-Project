{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8303fb7b",
   "metadata": {},
   "source": [
    "# Healthcare Data Cleaning Notebook\n",
    "## Introduction\n",
    "This notebook takes the raw (but previously cleaned) healthcare datasets and applies a series of cleaning and transformation steps based on our earlier analysis. The goal is to prepare the data for loading into a database or for further analysis. Each step is broken down into a separate cell for clarity.\n",
    "### Imports and Setup\n",
    "First, we import the necessary libraries. pandas is for data manipulation and os is for interacting with the file system (to create directories and manage file paths)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db214a20",
   "metadata": {},
   "source": [
    "Note: You may need to install pyarrow and sqlalchemy if you don't have them: pip install pyarrow sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf825f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sqlalchemy.dialects import postgresql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed28be",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Design Decision: Define input and output file paths as variables in a dedicated configuration cell.\n",
    "#### Why? \n",
    "This separates configuration from the core logic. Instead of hard-coding file paths deep inside the script, this design allows anyone (including your future self) to easily reuse this notebook for different data by only changing these two variables. It makes the code more maintainable and reusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475ba96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.path.join('..', 'cleaned_data')\n",
    "OUTPUT_DATA_DIR = os.path.join('..', 'v2cleaned_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef3e1c",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed8695",
   "metadata": {},
   "source": [
    "Load all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c14904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    observations = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"observations_cleaned.csv\"))\n",
    "    patients = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"patients_cleaned.csv\"))\n",
    "    procedures = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"procedures_cleaned.csv\"))\n",
    "    diagnoses = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"diagnoses_cleaned.csv\"))\n",
    "    encounters = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"encounters_cleaned.csv\"))\n",
    "    medications = pd.read_csv(os.path.join(INPUT_DATA_DIR, \"medications_cleaned.csv\"))\n",
    "    print(\"All datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"[ERROR] A data file was not found. Please check the input directory path. Details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7b18a",
   "metadata": {},
   "source": [
    "Lets double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b12597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>observation_code</th>\n",
       "      <th>observation_datetime</th>\n",
       "      <th>observation_description</th>\n",
       "      <th>observation_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>units</th>\n",
       "      <th>value_numeric</th>\n",
       "      <th>value_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f5f83a54-5883-413d-9bb4-c859fa6b8cde</td>\n",
       "      <td>4548-4</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Hemoglobin A1c/Hemoglobin.total in Blood</td>\n",
       "      <td>c70dc224-4c15-43ec-89b6-ed7821d80df2</td>\n",
       "      <td>ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb</td>\n",
       "      <td>%</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f5f83a54-5883-413d-9bb4-c859fa6b8cde</td>\n",
       "      <td>2345-7</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Glucose [Mass/Vol]</td>\n",
       "      <td>065df109-6962-496e-82a7-ab975746f265</td>\n",
       "      <td>ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f5f83a54-5883-413d-9bb4-c859fa6b8cde</td>\n",
       "      <td>2160-0</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Creatinine [Mass/Vol]</td>\n",
       "      <td>ea1a0317-d4cf-4f4c-9d3b-9e87700f67bc</td>\n",
       "      <td>ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a4345130-e167-45b5-9e60-75a1815d3ae0</td>\n",
       "      <td>8480-6</td>\n",
       "      <td>2026-04-08</td>\n",
       "      <td>Systolic blood pressure</td>\n",
       "      <td>8cd3eab8-0a7b-4e49-856c-ba2a081f969f</td>\n",
       "      <td>ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a4345130-e167-45b5-9e60-75a1815d3ae0</td>\n",
       "      <td>8462-4</td>\n",
       "      <td>2026-04-08</td>\n",
       "      <td>Diastolic blood pressure</td>\n",
       "      <td>31cb9c28-2bad-431a-b59a-6be7750e3184</td>\n",
       "      <td>ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           encounter_id observation_code observation_datetime  \\\n",
       "0  f5f83a54-5883-413d-9bb4-c859fa6b8cde           4548-4           2025-04-14   \n",
       "1  f5f83a54-5883-413d-9bb4-c859fa6b8cde           2345-7           2025-04-14   \n",
       "2  f5f83a54-5883-413d-9bb4-c859fa6b8cde           2160-0           2025-04-14   \n",
       "3  a4345130-e167-45b5-9e60-75a1815d3ae0           8480-6           2026-04-08   \n",
       "4  a4345130-e167-45b5-9e60-75a1815d3ae0           8462-4           2026-04-08   \n",
       "\n",
       "                    observation_description  \\\n",
       "0  Hemoglobin A1c/Hemoglobin.total in Blood   \n",
       "1                        Glucose [Mass/Vol]   \n",
       "2                     Creatinine [Mass/Vol]   \n",
       "3                   Systolic blood pressure   \n",
       "4                  Diastolic blood pressure   \n",
       "\n",
       "                         observation_id                            patient_id  \\\n",
       "0  c70dc224-4c15-43ec-89b6-ed7821d80df2  ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb   \n",
       "1  065df109-6962-496e-82a7-ab975746f265  ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb   \n",
       "2  ea1a0317-d4cf-4f4c-9d3b-9e87700f67bc  ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb   \n",
       "3  8cd3eab8-0a7b-4e49-856c-ba2a081f969f  ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb   \n",
       "4  31cb9c28-2bad-431a-b59a-6be7750e3184  ea3a68f6-ecf9-46aa-be97-7ecbfc7e7fcb   \n",
       "\n",
       "   units  value_numeric value_text  \n",
       "0      %            7.6        NaN  \n",
       "1  mg/dL          210.0        NaN  \n",
       "2  mg/dL            1.0        NaN  \n",
       "3   mmHg          101.0        NaN  \n",
       "4   mmHg           68.0        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1384ab",
   "metadata": {},
   "source": [
    "### Cleaning the patients Table\n",
    "This cell performs all cleaning and feature engineering steps for the patients data.\n",
    "Design Decisions:\n",
    "* Convert date_of_birth to datetime for calculations.\n",
    "* Convert zip_code to str to preserve format.\n",
    "* Standardize text case (.str.title(), .str.upper()) for consistency.\n",
    "* Convert gender to the memory-efficient category type.\n",
    "* Engineer an age column for better analysis, using a fixed date for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1059358",
   "metadata": {},
   "source": [
    "Correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1e8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['date_of_birth'] = pd.to_datetime(patients['date_of_birth'], errors='coerce')\n",
    "patients['zip_code'] = patients['zip_code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68a152",
   "metadata": {},
   "source": [
    "Standardize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0c7fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['first_name'] = patients['first_name'].str.title()\n",
    "patients['last_name'] = patients['last_name'].str.title()\n",
    "patients['city'] = patients['city'].str.title()\n",
    "patients['state'] = patients['state'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72502f",
   "metadata": {},
   "source": [
    "Use efficient data type for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d4ee8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['gender'] = patients['gender'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb4638",
   "metadata": {},
   "source": [
    "Feature Engineering: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbdddacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'patients' table cleaned and enhanced.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   address        150 non-null    object        \n",
      " 1   city           150 non-null    object        \n",
      " 2   date_of_birth  150 non-null    datetime64[ns]\n",
      " 3   first_name     150 non-null    object        \n",
      " 4   gender         150 non-null    category      \n",
      " 5   last_name      150 non-null    object        \n",
      " 6   patient_id     150 non-null    object        \n",
      " 7   phone_number   150 non-null    object        \n",
      " 8   state          150 non-null    object        \n",
      " 9   zip_code       150 non-null    object        \n",
      " 10  age            150 non-null    int64         \n",
      "dtypes: category(1), datetime64[ns](1), int64(1), object(8)\n",
      "memory usage: 12.1+ KB\n",
      "\n",
      "Sample of fully cleaned patients data:\n",
      "  first_name last_name                   city state  age\n",
      "0       Juan  Calderon           Sharpchester    MD   40\n",
      "1       Paul     Price  East Christophermouth    ND   43\n",
      "2      Julie     Brown           Jeffreyburgh    NH   74\n",
      "3      Sarah    Dillon             West Holly    AK   62\n",
      "4      Laura     Brown              Megantown    FL   82\n"
     ]
    }
   ],
   "source": [
    "analysis_date = pd.to_datetime('2025-06-27')\n",
    "patients['age'] = (analysis_date - patients['date_of_birth']).dt.days // 365\n",
    "\n",
    "print(\"'patients' table cleaned and enhanced.\")\n",
    "patients.info()\n",
    "print(\"\\nSample of fully cleaned patients data:\")\n",
    "print(patients[['first_name', 'last_name', 'city', 'state', 'age']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ca1b8",
   "metadata": {},
   "source": [
    "### Data Validation and Feature Engineering (encounters)\n",
    "Design Decisions:\n",
    "* Validate that discharge_date is not before admission_date to ensure data integrity.\n",
    "* Engineer a visit_duration_days column, which is more valuable for analysis than two separate date columns.\n",
    "### Why?\n",
    " Logical validation prevents \"impossible\" data from entering the database. Feature engineering creates direct analytical value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcceff46",
   "metadata": {},
   "source": [
    "Convert dates to the correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cbd81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters['admission_date'] = pd.to_datetime(encounters['admission_date'], errors='coerce')\n",
    "encounters['discharge_date'] = pd.to_datetime(encounters['discharge_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff59a4e",
   "metadata": {},
   "source": [
    "Validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fe3816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter date logic is valid.\n"
     ]
    }
   ],
   "source": [
    "invalid_dates = encounters[encounters['discharge_date'] < encounters['admission_date']]\n",
    "if not invalid_dates.empty:\n",
    "    print(f\"[WARNING] Found {len(invalid_dates)} encounters with discharge date before admission date.\")\n",
    "else:\n",
    "    print(\"Encounter date logic is valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267f84e",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be86c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'visit_duration_days' column created.\n",
      "  admission_date discharge_date  visit_duration_days\n",
      "0     2025-04-12     2025-04-12                    0\n",
      "1     2026-04-08     2026-04-08                    0\n",
      "2     2008-09-19     2008-09-19                    0\n",
      "3     2008-12-14     2008-12-14                    0\n",
      "4     2000-06-21     2000-06-21                    0\n"
     ]
    }
   ],
   "source": [
    "encounters['visit_duration_days'] = (encounters['discharge_date'] - encounters['admission_date']).dt.days\n",
    "print(\"'visit_duration_days' column created.\")\n",
    "print(encounters[['admission_date', 'discharge_date', 'visit_duration_days']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27122caa",
   "metadata": {},
   "source": [
    "### Advanced Cleaning and Outlier Detection (observations)\n",
    "Design Decisions:\n",
    "* Detect outliers using the robust IQR method.\n",
    "* Create a new boolean is_outlier column instead of deleting data.\n",
    "#### Why? \n",
    "In medical data, an extreme value might be a data error or a critical event. Deleting it is risky. Flagging the data is a safer, non-destructive approach that preserves all original information while allowing analysts to easily filter if they choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd27e9",
   "metadata": {},
   "source": [
    "Convert date to the correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0c748ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations['observation_datetime'] = pd.to_datetime(observations['observation_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b81416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_outliers(df, column):\n",
    "    \"\"\"Flags outliers in a specified column of a DataFrame using the IQR method.\"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6ea5",
   "metadata": {},
   "source": [
    "Apply the function to the numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "814740ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations['is_outlier'] = flag_outliers(observations, 'value_numeric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d1331",
   "metadata": {},
   "source": [
    "CORRECTED: Fill NaN using the recommended syntax to avoid warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799ef4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged 9 potential outliers in 'value_numeric'.\n",
      "\n",
      "Sample of observations with outlier flag:\n",
      "    observation_description  value_numeric  is_outlier\n",
      "173      Glucose [Mass/Vol]          245.0        True\n",
      "205      Glucose [Mass/Vol]          249.0        True\n",
      "315      Glucose [Mass/Vol]          241.0        True\n",
      "416      Glucose [Mass/Vol]          248.0        True\n",
      "503      Glucose [Mass/Vol]          238.0        True\n"
     ]
    }
   ],
   "source": [
    "observations['is_outlier'] = observations['is_outlier'].fillna(False)\n",
    "\n",
    "outlier_count = observations['is_outlier'].sum()\n",
    "print(f\"Flagged {outlier_count} potential outliers in 'value_numeric'.\")\n",
    "print(\"\\nSample of observations with outlier flag:\")\n",
    "print(observations.loc[observations['is_outlier'], ['observation_description', 'value_numeric', 'is_outlier']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc10da",
   "metadata": {},
   "source": [
    "### Cleaning Remaining DataFrames (procedures, diagnoses, medications)\n",
    "Design Decision: Process the remaining tables, handling their specific data types and missing values as determined in our analysis.\n",
    "#### Why?\n",
    " Each table has unique characteristics. We apply the specific logic needed for each one: converting dates, and for medications, correctly handling missing dosage (a quality issue) and end_date (a feature, not a bug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48b0968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures['date_performed'] = pd.to_datetime(procedures['date_performed'], errors='coerce')\n",
    "diagnoses['date_recorded'] = pd.to_datetime(diagnoses['date_recorded'], errors='coerce')\n",
    "\n",
    "medications['start_date'] = pd.to_datetime(medications['start_date'], errors='coerce')\n",
    "medications['end_date'] = pd.to_datetime(medications['end_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030f69c",
   "metadata": {},
   "source": [
    "Fill missing dosage with 'Unknown' - this is a data quality issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "568370d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erwin\\AppData\\Local\\Temp\\ipykernel_11248\\946811579.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  medications['dosage'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "medications['dosage'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd23ea",
   "metadata": {},
   "source": [
    "CORRECTED: Check for 'Unknown' with the correct spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2a82602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 records with dosage filled as 'Unknown'.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(medications[medications['dosage'] == 'Unknown'])} records with dosage filled as 'Unknown'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57c271",
   "metadata": {},
   "source": [
    "Missing end_date means the prescription is active - we leave it as NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36b8a7",
   "metadata": {},
   "source": [
    "### Preparing Data for PostgreSQL\n",
    "Design Decision: Save the final DataFrames as Parquet files instead of CSV.\n",
    "Why? This is a critical data engineering best practice.\n",
    "* CSV (The Alternative): CSV files are just plain text. They do not store metadata. When you save a DataFrame as a CSV, all data types are lost. 2025-06-27 becomes a simple string \"2025-06-27\". Your teammate would have to guess the correct data types, which often leads to errors.\n",
    "* Parquet (Our Choice): Parquet is a modern, columnar file format designed for efficiency and data-aware systems. It saves the schema (the column names and their data types) along with the data. This makes the data handoff much more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef8be56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\observations.parquet\n",
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\patients.parquet\n",
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\procedures.parquet\n",
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\diagnoses.parquet\n",
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\encounters.parquet\n",
      "Successfully saved cleaned data to: ..\\v2cleaned_data\\medications.parquet\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"observations\": observations,\n",
    "    \"patients\": patients,\n",
    "    \"procedures\": procedures,\n",
    "    \"diagnoses\": diagnoses,\n",
    "    \"encounters\": encounters,\n",
    "    \"medications\": medications\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # Trim whitespace from all object (string) columns before saving\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if df[col].notna().any():\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "    # Define the output path\n",
    "    output_path = os.path.join(OUTPUT_DATA_DIR, f\"{name}.parquet\")\n",
    "\n",
    "    # Save the cleaned dataframe to a new Parquet file\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    print(f\"Successfully saved cleaned data to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
